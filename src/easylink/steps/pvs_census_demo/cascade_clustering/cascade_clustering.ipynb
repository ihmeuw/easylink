{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, copy, os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "from splink.duckdb.linker import DuckDBLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SIMULATED_CENSUS\"] = os.environ[\"REFERENCE_FILE\"] = \"/ihme/homes/pnast/repos/linker/sample_data/pvs_like_case_study/simulated_census_2030.parquet,/ihme/homes/pnast/repos/linker/sample_data/pvs_like_case_study/simulated_geobase_reference_file.parquet\"\n",
    "os.environ[\"BLOCKING_COLS\"] = \"zip3,geokey\"\n",
    "os.environ[\"MATCHING_COLS\"] = \"first_name_15,last_name_12,middle_initial,day_of_birth,month_of_birth,year_of_birth,street_number,street_name,unit_number,zipcode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path, file_format=None):\n",
    "    if file_format is None:\n",
    "        file_format = file_path.split(\".\")[-1]\n",
    "    if file_format == \"parquet\":\n",
    "        return pd.read_parquet(file_path)\n",
    "    if file_format == \"csv\":\n",
    "        return pd.read_csv(file_path)\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2030_path = os.environ[\"SIMULATED_CENSUS\"].split(\",\")[0]\n",
    "reference_file_path = os.environ[\"REFERENCE_FILE\"].split(\",\")[1]\n",
    "census_2030 = load_file(census_2030_path)\n",
    "reference_file = load_file(reference_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2030_raw_input = census_2030.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11029"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(census_2030.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 nicknames in the Census\n"
     ]
    }
   ],
   "source": [
    "# Nickname processing\n",
    "# Have not yet found a nickname list in PVS docs,\n",
    "# so we do a minimal version for now -- could use\n",
    "# another list such as the one in pseudopeople\n",
    "# These examples all come directly from examples in the descriptions of PVS\n",
    "nickname_standardizations = {\n",
    "    \"Bill\": \"William\",\n",
    "    \"Chuck\": \"Charles\",\n",
    "    \"Charlie\": \"Charles\",\n",
    "    \"Cathy\": \"Catherine\",\n",
    "    \"Matt\": \"Matthew\",\n",
    "}\n",
    "has_nickname = census_2030.first_name.isin(nickname_standardizations.keys())\n",
    "print(f'{has_nickname.sum()} nicknames in the Census')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2030 = pd.concat([\n",
    "    census_2030,\n",
    "    census_2030[has_nickname].assign(first_name=lambda df: df.first_name.replace(nickname_standardizations))\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11033"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(census_2030.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The above will introduce duplicates on record_id, so we redefine\n",
    "# record_id to be unique (without getting rid of the original, input file record ID)\n",
    "def add_unique_id_col(df, col_name='unique_id', value_prefix=''):\n",
    "    return df.reset_index().rename(columns={'index': col_name}).assign(**{col_name: lambda df: value_prefix + df[col_name].astype(str)})\n",
    "\n",
    "def add_unique_record_id(df, dataset_name):\n",
    "    return add_unique_id_col(df, col_name='record_id', value_prefix=f'{dataset_name}_')\n",
    "\n",
    "census_2030 = add_unique_record_id(\n",
    "    census_2030.rename(columns={'record_id': 'record_id_raw_input_file'}),\n",
    "    \"census_2030_preprocessed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_address_part(column):\n",
    "    return (\n",
    "        column\n",
    "            # Remove leading or trailing whitespace\n",
    "            .str.strip()\n",
    "            # Turn any strings of consecutive whitespace into a single space\n",
    "            .str.replace('\\s+', ' ', regex=True)\n",
    "            # Normalize case\n",
    "            .str.upper()\n",
    "            # Normalize the word street as described in the example quoted above\n",
    "            # In reality, there would be many rules like this\n",
    "            .str.replace('\\b(STREET|STR)\\b', 'ST', regex=True)\n",
    "            # Make sure missingness is represented consistently\n",
    "            .replace('', pd.NA)\n",
    "    )\n",
    "\n",
    "address_cols = ['street_number', 'street_name', 'unit_number', 'city', 'state', 'zipcode']\n",
    "for address_col in address_cols:\n",
    "    census_2030[address_col] = census_2030[address_col].pipe(standardize_address_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2030 = census_2030[\n",
    "    census_2030.first_name.notnull() |\n",
    "    census_2030.last_name.notnull()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_file = reference_file.rename(columns=lambda c: c.replace('mailing_address_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dob(df, date_format='%Y%m%d'):\n",
    "    df = df.copy()\n",
    "    # Have to be floats because we want to treat as numeric for assessing similarity\n",
    "    # Note that as of now, none of our pseudopeople noise types would change the punctuation (\"/\") in the date, but\n",
    "    # they can insert non-numeric characters here or otherwise create invalid dates, in which case we fail to parse the date\n",
    "    # and treat it as missing.\n",
    "    dob = pd.to_datetime(df.date_of_birth, format=date_format, errors='coerce')\n",
    "    df['month_of_birth'] = dob.dt.month\n",
    "    df['year_of_birth'] = dob.dt.year\n",
    "    df['day_of_birth'] = dob.dt.day\n",
    "    return df.drop(columns=['date_of_birth'])\n",
    "\n",
    "census_2030 = split_dob(census_2030, date_format='%m/%d/%Y')\n",
    "reference_file = split_dob(reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't fully understand the purpose of blocking on the geokey,\n",
    "# as opposed to just blocking on its constituent columns.\n",
    "# Maybe it is a way of dealing with missingness in those constituent\n",
    "# columns (e.g. so an address with no unit number can still be blocked on geokey)?\n",
    "\n",
    "def add_geokey(df):\n",
    "    df = df.copy()\n",
    "    strings = [\n",
    "            df.street_number, ' ',\n",
    "            df.street_name, ' ',\n",
    "            df.unit_number.fillna(''), ' ',\n",
    "            df.city, ' ',\n",
    "            df.state.astype(str), ' ',\n",
    "            df.zipcode,\n",
    "        ]\n",
    "    geokey_str = ''\n",
    "    for string in strings:\n",
    "        geokey_str += string\n",
    "    df['geokey'] = geokey_str\n",
    "    # Normalize the whitespace -- necessary if the unit number was null\n",
    "    df['geokey'] = (\n",
    "        df.geokey.str.replace('\\s+', ' ', regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "reference_file = add_geokey(reference_file)\n",
    "census_2030 = add_geokey(census_2030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layne, Wagner, and Rothhaas p. 26: the name matching variables are\n",
    "# First 15 characters First Name, First 15 characters Middle Name, First 12 characters Last Name\n",
    "# Additionally, there are blocking columns for all of 1-3 initial characters of First/Last.\n",
    "# We don't have a full middle name in pseudopeople (nor would that be present in a real CUF)\n",
    "# so we have to stick to the first initial for middle.\n",
    "def add_truncated_name_cols(df):\n",
    "    df = df.copy()\n",
    "    df['first_name_15'] = df.first_name.str[:15]\n",
    "    df['last_name_12'] = df.last_name.str[:12]\n",
    "\n",
    "    if 'middle_name' in df.columns and 'middle_initial' not in df.columns:\n",
    "        df['middle_initial'] = df.middle_name.str[:1]\n",
    "\n",
    "    for num_chars in [1, 2, 3]:\n",
    "        df[f'first_name_{num_chars}'] = df.first_name.str[:num_chars]\n",
    "        df[f'last_name_{num_chars}'] = df.last_name.str[:num_chars]\n",
    "\n",
    "    return df\n",
    "\n",
    "census_2030 = add_truncated_name_cols(census_2030)\n",
    "reference_file = add_truncated_name_cols(reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layne, Wagner, and Rothhaas p. 26: phonetics are used in blocking (not matching)\n",
    "# - Soundex for Street Name\n",
    "# - NYSIIS code for First Name\n",
    "# - NYSIIS code for Last Name\n",
    "# - Reverse Soundex for First Name\n",
    "# - Reverse Soundex for Last Name\n",
    "\n",
    "def nysiis(input_string):\n",
    "    result = jellyfish.nysiis(input_string)\n",
    "    if result is None:\n",
    "        return pd.NA\n",
    "\n",
    "    return result\n",
    "\n",
    "def soundex(input_string):\n",
    "    result = jellyfish.soundex(input_string)\n",
    "    if result is None:\n",
    "        return pd.NA\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_name_phonetics(df):\n",
    "    df = df.copy()\n",
    "    for col in ['first_name', 'last_name']:\n",
    "        kwargs = {}\n",
    "        df[f'{col}_nysiis'] = df[col].dropna().apply(nysiis, **kwargs)\n",
    "        df[f'{col}_reverse_soundex'] = df[col].dropna().str[::-1].apply(soundex, **kwargs)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_address_phonetics(df):\n",
    "    df = df.copy()\n",
    "    kwargs = {}\n",
    "    df['street_name_soundex'] = df.street_name.dropna().apply(jellyfish.soundex, **kwargs)\n",
    "    return df\n",
    "\n",
    "census_2030 = add_name_phonetics(census_2030)\n",
    "census_2030 = add_address_phonetics(census_2030)\n",
    "reference_file = add_address_phonetics(reference_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zip3(df):\n",
    "    return df.assign(zip3=lambda x: x.zipcode.str[:3])\n",
    "\n",
    "def add_first_last_initial_categories(df):\n",
    "    # Page 20 of the NORC report: \"Name-cuts are defined by combinations of the first characters of the first and last names. The twenty letter groupings\n",
    "    # for the first character are: A-or-blank, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, and U-Z.\"\n",
    "    initial_cut = lambda x: x.fillna('A').str[0].replace('A', 'A-or-blank').replace(['U', 'V', 'W', 'X', 'Y', 'Z'], 'U-Z')\n",
    "    return df.assign(first_initial_cut=lambda x: initial_cut(x.first_name), last_initial_cut=lambda x: initial_cut(x.last_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2030 = add_zip3(census_2030)\n",
    "census_2030 = add_first_last_initial_categories(census_2030)\n",
    "reference_file = add_zip3(reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"splink_model_params.json\", \"r\") as f:\n",
    "    splink_settings = json.load(f)\n",
    "\n",
    "PROBABILITY_THRESHOLD = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = [c for c in reference_file.columns if c in census_2030.columns]\n",
    "reference_file_index_of_ids = reference_file.reset_index().set_index(\"record_id\")[\"index\"]\n",
    "census_index_of_ids = census_2030.reset_index().set_index(\"record_id\")[\"index\"]\n",
    "\n",
    "def prep_table_for_splink(df, dataset_name):\n",
    "    return df[common_cols].assign(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvs_matching_pass(blocking_cols, matching_cols):\n",
    "    tables_for_splink = [\n",
    "        prep_table_for_splink(reference_file, \"reference_file\"),\n",
    "        prep_table_for_splink(census_2030[census_2030.pik.isnull()], \"census_2030\"),\n",
    "    ]\n",
    "    pass_splink_settings = copy.deepcopy(splink_settings)\n",
    "    pass_splink_settings[\"comparisons\"] = [\n",
    "            c for c in pass_splink_settings[\"comparisons\"] if c[\"output_column_name\"] in matching_cols\n",
    "        ]\n",
    "    \n",
    "    blocking_rule_parts = [f\"l.{col} = r.{col}\" for col in blocking_cols]\n",
    "    blocking_rule = \" and \".join(blocking_rule_parts)\n",
    "    linker = DuckDBLinker(\n",
    "        tables_for_splink,\n",
    "        {\n",
    "            **pass_splink_settings,\n",
    "            **{\n",
    "                \"blocking_rules_to_generate_predictions\": [blocking_rule],\n",
    "            },\n",
    "        },\n",
    "        # Must match order of tables_for_splink\n",
    "        input_table_aliases=[\"reference_file\", \"census_2030\"],\n",
    "    )\n",
    "\n",
    "    potential_links = linker.predict(\n",
    "        threshold_match_probability=PROBABILITY_THRESHOLD\n",
    "    ).as_pandas_dataframe()\n",
    "    # Name the columns better than \"_r\" and \"_l\"\n",
    "    # In practice it seems to always be one dataset on the right and another on the left,\n",
    "    # but it's \"backwards\" relative to the order above and I don't want to rely on it\n",
    "    potential_links_census_left = potential_links[\n",
    "        potential_links.source_dataset_l == \"census_2030\"\n",
    "    ]\n",
    "    assert (potential_links_census_left.source_dataset_r == \"reference_file\").all()\n",
    "    potential_links_census_left = potential_links_census_left.rename(\n",
    "        columns=lambda c: re.sub(\"_l$\", \"_census_2030\", c)\n",
    "    ).rename(columns=lambda c: re.sub(\"_r$\", \"_reference_file\", c))\n",
    "\n",
    "    potential_links_reference_left = potential_links[\n",
    "        potential_links.source_dataset_l == \"reference_file\"\n",
    "    ]\n",
    "    assert (potential_links_reference_left.source_dataset_r == \"census_2030\").all()\n",
    "    potential_links_reference_left = potential_links_reference_left.rename(\n",
    "        columns=lambda c: re.sub(\"_l$\", \"_reference_file\", c)\n",
    "    ).rename(columns=lambda c: re.sub(\"_r$\", \"_census_2030\", c))\n",
    "\n",
    "    assert len(potential_links) == len(potential_links_census_left) + len(\n",
    "        potential_links_reference_left\n",
    "    )\n",
    "    potential_links = pd.concat(\n",
    "        [potential_links_census_left, potential_links_reference_left], ignore_index=True\n",
    "    )\n",
    "\n",
    "    print(f\"{len(potential_links)} links above threshold\")\n",
    "\n",
    "    # Post-processing: deal with multiple matches\n",
    "    # According to the report, a record is considered not linkable if it has multiple matches above the threshold\n",
    "    # I represent \"not linkable\" here with a PIK of -1 (different from NaN, which means yet-to-be-linked)\n",
    "    potential_links = potential_links.merge(\n",
    "        reference_file[[\"record_id\", \"pik\"]],\n",
    "        left_on=\"record_id_reference_file\",\n",
    "        right_on=\"record_id\",\n",
    "        how=\"left\",\n",
    "    ).drop(columns=[\"record_id\"])\n",
    "    print(f\"{potential_links.record_id_census_2030.nunique()} input records have a match\")\n",
    "    census_records_with_multiple_potential_piks = (\n",
    "        potential_links.groupby(\"record_id_census_2030\")\n",
    "        .pik.nunique()\n",
    "        .pipe(lambda c: c[c > 1])\n",
    "        .index\n",
    "    )\n",
    "    if len(census_records_with_multiple_potential_piks) > 0:\n",
    "        print(\n",
    "            f\"{len(census_records_with_multiple_potential_piks)} input records matched to multiple PIKs, marking as unlinkable\"\n",
    "        )\n",
    "\n",
    "    potential_links.loc[\n",
    "        potential_links.record_id_census_2030.isin(\n",
    "            census_records_with_multiple_potential_piks\n",
    "        ),\n",
    "        \"pik\",\n",
    "    ] = -1\n",
    "\n",
    "    assert (potential_links.groupby(\"record_id_census_2030\").pik.nunique() == 1).all()\n",
    "    links = potential_links.groupby(\"record_id_census_2030\").pik.first().reset_index()\n",
    "    census_2030.loc[\n",
    "        census_index_of_ids.loc[links.record_id_census_2030], \"pik\"\n",
    "    ] = links.pik.values.astype(int)\n",
    "\n",
    "    print(\n",
    "        f\"Matched {len(links)} records; {census_2030.pik.isnull().mean():.2%} still eligible to match\"\n",
    "    )\n",
    "\n",
    "    # Diagnostic showing the predicted values for each combination of column similarity values\n",
    "    all_predictions = linker.predict().as_pandas_dataframe()\n",
    "    all_combos = (\n",
    "        all_predictions.groupby(list(all_predictions.filter(like=\"gamma_\").columns))\n",
    "        .match_probability.agg([\"mean\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "\n",
    "    return all_combos, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pik' not in census_2030.columns:\n",
    "    # If 'pik' column does not exist, create it and fill all its rows with np.nan\n",
    "    census_2030['pik'] = np.nan\n",
    "    census_2030[\"pik\"] = census_2030[\"pik\"].astype('Int64')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11031"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(census_2030.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8795 links above threshold\n",
      "8094 input records have a match\n",
      "549 input records matched to multiple PIKs, marking as unlinkable\n",
      "Matched 8094 records; 26.62% still eligible to match\n"
     ]
    }
   ],
   "source": [
    "blocking_cols = os.getenv(\"BLOCKING_COLS\").split(\",\")\n",
    "matching_cols = os.getenv(\"MATCHING_COLS\").split(\",\")\n",
    "all_combos, pik_pairs = pvs_matching_pass(blocking_cols, matching_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = os.getenv(\n",
    "    \"DUMMY_CONTAINER_OUTPUT_PATHS\")[0]\n",
    "# output_file_path = \"scratch.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2030[\"pik\"] = census_2030[\"pik\"].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>household_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_initial</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>street_number</th>\n",
       "      <th>street_name</th>\n",
       "      <th>unit_number</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>housing_type</th>\n",
       "      <th>relationship_to_reference_person</th>\n",
       "      <th>sex</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>year</th>\n",
       "      <th>pik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulated_census_2030_0</td>\n",
       "      <td>0_8033</td>\n",
       "      <td>Gerald</td>\n",
       "      <td>R</td>\n",
       "      <td>Allen</td>\n",
       "      <td>86</td>\n",
       "      <td>11/03/1943</td>\n",
       "      <td>1130</td>\n",
       "      <td>mallory ln</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2030</td>\n",
       "      <td>89484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simulated_census_2030_1</td>\n",
       "      <td>0_1066</td>\n",
       "      <td>April</td>\n",
       "      <td>S</td>\n",
       "      <td>Hayden</td>\n",
       "      <td>33</td>\n",
       "      <td>10/23/1996</td>\n",
       "      <td>32597</td>\n",
       "      <td>delacorte dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Other nonrelative</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>2030</td>\n",
       "      <td>98736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simulated_census_2030_2</td>\n",
       "      <td>0_1066</td>\n",
       "      <td>Loretta</td>\n",
       "      <td>T</td>\n",
       "      <td>Lowe</td>\n",
       "      <td>71</td>\n",
       "      <td>06/01/1958</td>\n",
       "      <td>32597</td>\n",
       "      <td>delacorte dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2030</td>\n",
       "      <td>91258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simulated_census_2030_3</td>\n",
       "      <td>0_2514</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>A</td>\n",
       "      <td>Sorrentino</td>\n",
       "      <td>75</td>\n",
       "      <td>03/18/1954</td>\n",
       "      <td>4458</td>\n",
       "      <td>wibdsor pl</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>Multiracial or Other</td>\n",
       "      <td>2030</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simulated_census_2030_4</td>\n",
       "      <td>0_5627</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>S</td>\n",
       "      <td>Baker</td>\n",
       "      <td>44</td>\n",
       "      <td>05/20/1985</td>\n",
       "      <td>None</td>\n",
       "      <td>winding trail rd</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Other nonrelative</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>2030</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>simulated_census_2030_11024</td>\n",
       "      <td>0_10778</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>T</td>\n",
       "      <td>Boyd</td>\n",
       "      <td>46</td>\n",
       "      <td>07/01/1983</td>\n",
       "      <td>211</td>\n",
       "      <td>quiet wsy</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2030</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11029</th>\n",
       "      <td>simulated_census_2030_11025</td>\n",
       "      <td>0_11001</td>\n",
       "      <td>Wendy</td>\n",
       "      <td>M</td>\n",
       "      <td>Gross</td>\n",
       "      <td>54</td>\n",
       "      <td>12/05/1975</td>\n",
       "      <td>2801</td>\n",
       "      <td>blje rdv dr n</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2030</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030</th>\n",
       "      <td>simulated_census_2030_11026</td>\n",
       "      <td>0_5308</td>\n",
       "      <td>Ember</td>\n",
       "      <td>H</td>\n",
       "      <td>Samuels</td>\n",
       "      <td>10</td>\n",
       "      <td>10/26/2019</td>\n",
       "      <td>24113</td>\n",
       "      <td>lauder</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>2030</td>\n",
       "      <td>104164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11031</th>\n",
       "      <td>simulated_census_2030_11027</td>\n",
       "      <td>0_10693</td>\n",
       "      <td>Athena</td>\n",
       "      <td>V</td>\n",
       "      <td>Deshpande</td>\n",
       "      <td>27</td>\n",
       "      <td>07/05/2002</td>\n",
       "      <td>1534</td>\n",
       "      <td>bentley dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Reference person</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2030</td>\n",
       "      <td>106182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11032</th>\n",
       "      <td>simulated_census_2030_11028</td>\n",
       "      <td>0_10693</td>\n",
       "      <td>Zechariah</td>\n",
       "      <td>C</td>\n",
       "      <td>Deshpande</td>\n",
       "      <td>0</td>\n",
       "      <td>04/10/2029</td>\n",
       "      <td>1534</td>\n",
       "      <td>bentley dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Anytown</td>\n",
       "      <td>WA</td>\n",
       "      <td>00000</td>\n",
       "      <td>Household</td>\n",
       "      <td>Biological child</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2030</td>\n",
       "      <td>107923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11033 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         record_id household_id first_name middle_initial  \\\n",
       "0          simulated_census_2030_0       0_8033     Gerald              R   \n",
       "1          simulated_census_2030_1       0_1066      April              S   \n",
       "2          simulated_census_2030_2       0_1066    Loretta              T   \n",
       "3          simulated_census_2030_3       0_2514     Sandra              A   \n",
       "4          simulated_census_2030_4       0_5627      Bobby              S   \n",
       "...                            ...          ...        ...            ...   \n",
       "11028  simulated_census_2030_11024      0_10778     Jeremy              T   \n",
       "11029  simulated_census_2030_11025      0_11001      Wendy              M   \n",
       "11030  simulated_census_2030_11026       0_5308      Ember              H   \n",
       "11031  simulated_census_2030_11027      0_10693     Athena              V   \n",
       "11032  simulated_census_2030_11028      0_10693  Zechariah              C   \n",
       "\n",
       "        last_name age date_of_birth street_number       street_name  \\\n",
       "0           Allen  86    11/03/1943          1130        mallory ln   \n",
       "1          Hayden  33    10/23/1996         32597      delacorte dr   \n",
       "2            Lowe  71    06/01/1958         32597      delacorte dr   \n",
       "3      Sorrentino  75    03/18/1954          4458        wibdsor pl   \n",
       "4           Baker  44    05/20/1985          None  winding trail rd   \n",
       "...           ...  ..           ...           ...               ...   \n",
       "11028        Boyd  46    07/01/1983           211         quiet wsy   \n",
       "11029       Gross  54    12/05/1975          2801     blje rdv dr n   \n",
       "11030     Samuels  10    10/26/2019         24113            lauder   \n",
       "11031   Deshpande  27    07/05/2002          1534        bentley dr   \n",
       "11032   Deshpande   0    04/10/2029          1534        bentley dr   \n",
       "\n",
       "      unit_number     city state zipcode housing_type  \\\n",
       "0            None  Anytown    WA   00000    Household   \n",
       "1            None  Anytown    WA   00000    Household   \n",
       "2            None  Anytown    WA   00000    Household   \n",
       "3            None  Anytown    WA   00000    Household   \n",
       "4            None  Anytown    WA   00000    Household   \n",
       "...           ...      ...   ...     ...          ...   \n",
       "11028        None  Anytown    WA   00000    Household   \n",
       "11029        None  Anytown    WA   00000    Household   \n",
       "11030        None  Anytown    WA   00000    Household   \n",
       "11031        None  Anytown    WA   00000    Household   \n",
       "11032        None  Anytown    WA   00000    Household   \n",
       "\n",
       "      relationship_to_reference_person     sex        race_ethnicity  year  \\\n",
       "0                     Reference person    Male                 Black  2030   \n",
       "1                    Other nonrelative  Female                 Black  2030   \n",
       "2                     Reference person  Female                 White  2030   \n",
       "3                     Reference person  Female  Multiracial or Other  2030   \n",
       "4                    Other nonrelative    Male                 White  2030   \n",
       "...                                ...     ...                   ...   ...   \n",
       "11028                 Reference person    Male                 Black  2030   \n",
       "11029                 Reference person  Female                 White  2030   \n",
       "11030                 Reference person  Female                 Black  2030   \n",
       "11031                 Reference person  Female                 Asian  2030   \n",
       "11032                 Biological child    Male                 Asian  2030   \n",
       "\n",
       "          pik  \n",
       "0       89484  \n",
       "1       98736  \n",
       "2       91258  \n",
       "3        <NA>  \n",
       "4        <NA>  \n",
       "...       ...  \n",
       "11028    <NA>  \n",
       "11029    <NA>  \n",
       "11030  104164  \n",
       "11031  106182  \n",
       "11032  107923  \n",
       "\n",
       "[11033 rows x 19 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pd.merge(census_2030_raw_input, census_2030[['record_id_raw_input_file', 'pik']], left_on='record_id', right_on='record_id_raw_input_file',how='left', suffixes=(\"_raw\",\"_updated\"))\n",
    "final_output.drop(columns=[\"record_id_raw_input_file\"], inplace=True)\n",
    "if \"pik\" in census_2030_raw_input:\n",
    "    # Maybe show \"bad cases\" through validation errors\n",
    "    final_output = final_output.rename(columns={\"pik_updated\":\"pik\"}).drop(columns=[\"pik_raw\"])\n",
    "final_output.to_parquet(output_file_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
